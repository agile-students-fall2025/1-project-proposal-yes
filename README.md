# Project Proposal: GestureTalk
## Team Members
- [Iva Park](https://github.com/ivapark)
- [Jasmine Fan](https://github.com/jasmine7310)
- [Terry Cao](https://github.com/cao-exe)
- [Walker Tupman](https://github.com/bestole)
- [Venetia Liu](https://github.com/venetialiu)

## What and why?
**GestureTalk** is a web app that takes live camera footage of sign language and turns it into a short summary of what was signed. GestureTalk would recognize simple hand gestures through a web cam and display translated short summary captions.

We want to build a sign language interpreter for the sake of accessibility. A person who understands sign language and can readily translate it is not always available. So, by using GestureTalk, anyone can translate sign language to text.
## For whom?
GestureTalk's end-users/ customers would be the deaf/ hard-of-hearing, business owners who have a significant amount of employyes who use sign language as a main form of communication, and people who don't know sign language and need to have an on-hand interpreter.
## How?
When the end-user interacts with our web app, the user must give consent to their camera feed being used. Once accepted, the user can gesture/ speak in sign language, which is captured by the camera. While the user is gesturing, a translation will appear on the screen in text. 
## Scope
The project incorporates front-end and back-end work enough for 4-5 people to work on for a semester due to it being a significant challenge in the back-end. However, it is of note that this project would not be difficult to the point of uncompletion because we only deal with sign language to text translation, and not both sign to text and text to sign.

This project of course, will have to deal with hand recognition AI/ML in order to translate the sign language into text. We forecast that this would be the major focus of our efforts for this semester. Nonetheless, we are confident that we will be able to surmount this hurdle. 